{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization Techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Wordnet Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91780\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91780\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnetLemmatizng = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    \"running\", \"runner\", \"ran\",\n",
    "    \"played\", \"playing\", \"plays\",\n",
    "    \"connected\", \"connecting\", \"connection\",\n",
    "    \"caring\", \"cared\", \"cares\",\n",
    "    \"studies\", \"studying\", \"studied\",\n",
    "    \"walking\", \"walked\", \"walks\",\n",
    "    \"creation\", \"creating\", \"creates\",\n",
    "    \"relational\", \"related\", \"relating\",\n",
    "    \"crying\", \"cried\", \"cries\",\n",
    "    \"bigger\", \"biggest\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ---> running\n",
      "runner ---> runner\n",
      "ran ---> ran\n",
      "played ---> played\n",
      "playing ---> playing\n",
      "plays ---> play\n",
      "connected ---> connected\n",
      "connecting ---> connecting\n",
      "connection ---> connection\n",
      "caring ---> caring\n",
      "cared ---> cared\n",
      "cares ---> care\n",
      "studies ---> study\n",
      "studying ---> studying\n",
      "studied ---> studied\n",
      "walking ---> walking\n",
      "walked ---> walked\n",
      "walks ---> walk\n",
      "creation ---> creation\n",
      "creating ---> creating\n",
      "creates ---> creates\n",
      "relational ---> relational\n",
      "related ---> related\n",
      "relating ---> relating\n",
      "crying ---> cry\n",
      "cried ---> cried\n",
      "cries ---> cry\n",
      "bigger ---> bigger\n",
      "biggest ---> biggest\n"
     ]
    }
   ],
   "source": [
    "#  By default the words the considered as Nouns, we can also change this using pos parameters which are nothing but parts of speech.\n",
    "for word in words:\n",
    "    print(word + \" ---> \" + wordnetLemmatizng.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ---> run\n",
      "runner ---> runner\n",
      "ran ---> run\n",
      "played ---> play\n",
      "playing ---> play\n",
      "plays ---> play\n",
      "connected ---> connect\n",
      "connecting ---> connect\n",
      "connection ---> connection\n",
      "caring ---> care\n",
      "cared ---> care\n",
      "cares ---> care\n",
      "studies ---> study\n",
      "studying ---> study\n",
      "studied ---> study\n",
      "walking ---> walk\n",
      "walked ---> walk\n",
      "walks ---> walk\n",
      "creation ---> creation\n",
      "creating ---> create\n",
      "creates ---> create\n",
      "relational ---> relational\n",
      "related ---> relate\n",
      "relating ---> relate\n",
      "crying ---> cry\n",
      "cried ---> cry\n",
      "cries ---> cry\n",
      "bigger ---> bigger\n",
      "biggest ---> biggest\n"
     ]
    }
   ],
   "source": [
    "#  Here we are changing pos to 'v' ---> that means 'verb'\n",
    "for word in words:\n",
    "    print(word + \" ---> \" + wordnetLemmatizng.lemmatize(word, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ---> running\n",
      "runner ---> runner\n",
      "ran ---> ran\n",
      "played ---> played\n",
      "playing ---> playing\n",
      "plays ---> plays\n",
      "connected ---> connected\n",
      "connecting ---> connecting\n",
      "connection ---> connection\n",
      "caring ---> caring\n",
      "cared ---> cared\n",
      "cares ---> cares\n",
      "studies ---> studies\n",
      "studying ---> studying\n",
      "studied ---> studied\n",
      "walking ---> walking\n",
      "walked ---> walked\n",
      "walks ---> walks\n",
      "creation ---> creation\n",
      "creating ---> creating\n",
      "creates ---> creates\n",
      "relational ---> relational\n",
      "related ---> related\n",
      "relating ---> relating\n",
      "crying ---> crying\n",
      "cried ---> cried\n",
      "cries ---> cries\n",
      "bigger ---> big\n",
      "biggest ---> big\n"
     ]
    }
   ],
   "source": [
    "# Here we are changing pos to 'a' ---> which means 'Adjective'\n",
    "for word in words:\n",
    "    print(word + \" ---> \" + wordnetLemmatizng.lemmatize(word, pos='a'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
